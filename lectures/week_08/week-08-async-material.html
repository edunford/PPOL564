<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>PPOL564 | Week 8 - Asynchronous lecture materials</title>

<script src="week-08-async-material_files/header-attrs-2.10/header-attrs.js"></script>
<script src="week-08-async-material_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="week-08-async-material_files/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="week-08-async-material_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="week-08-async-material_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="week-08-async-material_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="week-08-async-material_files/navigation-1.1/tabsets.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #232629;
    color: #7a7c7d;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #7a7c7d;  padding-left: 4px; }
div.sourceCode
  { color: #cfcfc2; background-color: #232629; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #cfcfc2; } /* Normal */
code span.al { color: #95da4c; background-color: #4d1f24; font-weight: bold; } /* Alert */
code span.an { color: #3f8058; } /* Annotation */
code span.at { color: #2980b9; } /* Attribute */
code span.bn { color: #f67400; } /* BaseN */
code span.bu { color: #7f8c8d; } /* BuiltIn */
code span.cf { color: #fdbc4b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #3daee9; } /* Char */
code span.cn { color: #27aeae; font-weight: bold; } /* Constant */
code span.co { color: #7a7c7d; } /* Comment */
code span.cv { color: #7f8c8d; } /* CommentVar */
code span.do { color: #a43340; } /* Documentation */
code span.dt { color: #2980b9; } /* DataType */
code span.dv { color: #f67400; } /* DecVal */
code span.er { color: #da4453; text-decoration: underline; } /* Error */
code span.ex { color: #0099ff; font-weight: bold; } /* Extension */
code span.fl { color: #f67400; } /* Float */
code span.fu { color: #8e44ad; } /* Function */
code span.im { color: #27ae60; } /* Import */
code span.in { color: #c45b00; } /* Information */
code span.kw { color: #cfcfc2; font-weight: bold; } /* Keyword */
code span.op { color: #cfcfc2; } /* Operator */
code span.ot { color: #27ae60; } /* Other */
code span.pp { color: #27ae60; } /* Preprocessor */
code span.re { color: #2980b9; background-color: #153042; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #da4453; } /* SpecialString */
code span.st { color: #f44f4f; } /* String */
code span.va { color: #27aeae; } /* Variable */
code span.vs { color: #da4453; } /* VerbatimString */
code span.wa { color: #da4453; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="async-page-style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore"><a href="http://ericdunford.com/ppol564/">Back to Course Website</a> <br><br>
<center>
Automated Heists <br> <em>Drawing from (Un-)Structured Data Sources</em>
</center></h1>
<h3 class="subtitle"><center>
PPOL 564 | Data Science I | Foundations <br><br> Lecture Materials for Week 8
</center>
<br></h3>
<h4 class="author"><center>
Professor Eric Dunford (<a href="mailto:ed769@georgetown.edu" class="email">ed769@georgetown.edu</a>) <br> McCourt School of Public Policy, Georgetown University <br><br>
</center></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#learning-objectives">Learning Objectives</a></li>
<li><a href="#installations">Installations</a></li>
<li><a href="#asynchronous-materials">Asynchronous Materials</a>
<ul>
<li><a href="#section">_</a></li>
<li><a href="#websites">Websites</a>
<ul>
<li><a href="#relevant-slides"><span><strong>Relevant Slides</strong></span></a></li>
</ul></li>
<li><a href="#scraping-web-content">Scraping Web Content</a>
<ul>
<li><a href="#code-from-the-video">Code from the video</a></li>
</ul></li>
<li><a href="#building-a-webscraper">Building a Webscraper</a>
<ul>
<li><a href="#code-from-the-video-1">Code from the video</a></li>
</ul></li>
<li><a href="#scraping-.pdf.docx">Scraping <code>.pdf</code>/<code>.docx</code></a>
<ul>
<li><a href="#code-from-the-video-2">Code from the video</a></li>
</ul></li>
</ul></li>
<li><a href="#practice">Practice</a>
<ul>
<li><a href="#section-1">_</a></li>
<li><a href="#question-1">Question 1</a>
<ul>
<li><a href="#section-2">_</a></li>
<li><a href="#answer">Answer</a></li>
</ul></li>
<li><a href="#question-2">Question 2</a>
<ul>
<li><a href="#section-3">_</a></li>
<li><a href="#answer-1">Answer</a></li>
</ul></li>
<li><a href="#question-3">Question 3</a>
<ul>
<li><a href="#section-4">_</a></li>
<li><a href="#answer-2">Answer</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<br>
<hr>
<p><br></p>
<div id="learning-objectives" class="section level1">
<h1>Learning Objectives</h1>
<p><br></p>
<p><strong>In the Asynchronous Lecture</strong></p>
<ul>
<li>Understanding <strong>html structure</strong> to look up content on a website</li>
<li><strong>Scrape</strong> content from a website and <strong>build a scraper</strong> to systematically draw content from similarly organized webpages.</li>
<li>Discuss scraping content from <strong>PDFs</strong> and <strong>Word</strong> documents.</li>
</ul>
<p><br></p>
<p><strong>In the Synchronous Lecture</strong></p>
<ul>
<li>Establishing a <strong><code>SQLite</code> connection</strong> in Python</li>
<li>Writing <code>SQLite</code> <strong>queries</strong></li>
<li>Building your own <strong>dataverse</strong> with <code>SQLite</code>.</li>
</ul>
<p><br></p>
<blockquote>
<p>If you have any questions while watching the pre-recorded material, be sure to <strong>write them down and to bring them up</strong> during the synchronous portion of the lecture.</p>
</blockquote>
<br>
<hr>
<p><br></p>
</div>
<div id="installations" class="section level1">
<h1>Installations</h1>
<p><br></p>
<p>In the synchronous lecture, we’ll be discussing writing SQLite queries. I’ll be using a simple SQL GUI to demonstrate different types of queries. If you wish to follow along in class, please install the <a href="https://sqlitebrowser.org/dl/"><strong>DB Browser for SQLite</strong></a> on your machine prior to class.</p>
<br>
<hr>
<p><br></p>
<!-- # Synchronous Materials -->
<!-- <br> -->
<!-- - _Download_: SQLite database used in the lecture -- [**country.sqlite**](https://www.dropbox.com/s/f6z3kpfpbr8xf1j/country.sqlite?dl=0) -->
<!-- - _Scripts_: -->
<!--   - <a href="synchronous-lecture-materials/intro_sql_commands.sql" download><strong>intro_sql_commands.sql</strong></a> -->
<!--   - <a href="synchronous-lecture-materials/using_sql_with_pandas.py" download><strong>using_sql_with_pandas.py</strong></a> -->
<!-- - _Breakout_: [**Practice with SQL queries**](breakout/breakout-sql-queries.html) -->
<!-- <br><hr><br> -->
</div>
<div id="asynchronous-materials" class="section level1 tabset tabset-pills">
<h1 class="tabset tabset-pills">Asynchronous Materials</h1>
<p><br></p>
<p><em>The following tabs contain pre-recorded lecture materials for class this week. Please review these materials prior to the synchronous lecture.</em></p>
<p><strong><em>Total time</em></strong>: Approx. 1 hour and 7 minutes</p>
<p><br></p>
<p><br></p>
<div id="section" class="section level2">
<h2>_</h2>
<br>
<hr>
<p><br></p>
</div>
<div id="websites" class="section level2">
<h2>Websites</h2>
<div id="relevant-slides" class="section level3">
<h3><a href="slides/webscraping.html"><strong>Relevant Slides</strong></a></h3>
<iframe src="https://georgetown.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=fa6dfbe0-6d12-4229-ac03-ac3e013aa2b3&amp;autoplay=false&amp;offerviewer=true&amp;showtitle=true&amp;showbrand=false&amp;start=0&amp;interactivity=all" height="506" width="900" style="border: 1px solid #464646;" allowfullscreen allow="autoplay">
</iframe>
<br>
<hr>
<p><br></p>
</div>
</div>
<div id="scraping-web-content" class="section level2">
<h2>Scraping Web Content</h2>
<p><br></p>
<iframe src="https://georgetown.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=6e34887e-7e80-4965-b901-ac3e013e1d00&amp;autoplay=false&amp;offerviewer=true&amp;showtitle=true&amp;showbrand=false&amp;start=0&amp;interactivity=all" height="506" width="900" style="border: 1px solid #464646;" allowfullscreen allow="autoplay">
</iframe>
<div id="code-from-the-video" class="section level3">
<h3>Code from the video</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests <span class="co"># For downloading the website</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup <span class="co"># For parsing the website</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># BBC Url that we&#39;ll scrape. </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">&quot;https://www.bbc.com/news/world-us-canada-54238936&quot;</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>page <span class="op">=</span> requests.get(url)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>page.status_code <span class="co"># 200 == Connection</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># We&#39;ve downloaded the entire website</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>page.content</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Parse the content </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>soup <span class="op">=</span> BeautifulSoup(page.content, <span class="st">&#39;html.parser&#39;</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s look at the raw code of the downloaded website</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(soup.prettify())</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># With the above in hand, we can find all instances of a tag at once.</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>soup.find_all(<span class="st">&#39;p&#39;</span>) <span class="co"># Here I&#39;m locating all the paragraph tags</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># We can then convert the tag to text</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>soup.find_all(<span class="st">&#39;p&#39;</span>)[<span class="dv">15</span>].get_text()</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Using a list comprehension we can do this for each paragraph tag</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>content1 <span class="op">=</span> [i.get_text() <span class="cf">for</span> i <span class="kw">in</span> soup.find_all(<span class="st">&#39;p&#39;</span>)]</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>content1</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># As we can see, we get things that we want and some things that we don&#39;t want.</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># So let&#39;s be more specific in targeting specific content.</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Can use a css selector to target specific content</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># #main-content &gt; div.ssrcss-1ocoo3l-Wrap.e42f8511 &gt; div &gt; div.ssrcss-rgov1k-MainColumn.e1sbfw0p0 &gt; article &gt; div:nth-child(3) &gt; div &gt; p &gt; b</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>story_content <span class="op">=</span> [i.get_text() <span class="cf">for</span> i <span class="kw">in</span> soup.select(<span class="st">&quot;article &gt; div &gt; div&quot;</span>)] </span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: Secret here is to remove the :nth-child(3) from div:nth-child(3). Think of :nth-child(3) as the </span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co"># index on the div tag. div:nth-child(3) says give me all items at position 3, whereas div give me all items at</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co"># this location. </span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Join together as a single string</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>story_text <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>.join(story_content)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(story_text)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Great! Now let&#39;s target different information like the headline and the date.</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Date CSS</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="co">#main-content &gt; div.ssrcss-1ocoo3l-Wrap.e42f8511 &gt; div &gt; div.ssrcss-rgov1k-MainColumn.e1sbfw0p0 &gt; article &gt; header &gt; div:nth-child(2) &gt; dl &gt; div &gt; dd &gt; span &gt; time</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>css_loc <span class="op">=</span> <span class="st">&quot;article &gt; header &gt; div:nth-child(2) &gt; dl &gt; div &gt; dd &gt; span &gt; time&quot;</span></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>story_date <span class="op">=</span> soup.select(css_loc)[<span class="dv">0</span>].get_text()</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Get story head line</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>story_headline <span class="op">=</span> soup.find_all(<span class="st">&quot;h1&quot;</span>)[<span class="dv">0</span>].get_text()</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Gather together</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>entry <span class="op">=</span> [story_headline,story_date,story_text]</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>entry</span></code></pre></div>
<br>
<hr>
<p><br></p>
</div>
</div>
<div id="building-a-webscraper" class="section level2">
<h2>Building a Webscraper</h2>
<p><br></p>
<iframe src="https://georgetown.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=05c13020-5c6f-429c-82ad-ac3e0143de96&amp;autoplay=false&amp;offerviewer=true&amp;showtitle=true&amp;showbrand=false&amp;start=0&amp;interactivity=all" height="506" width="900" style="border: 1px solid #464646;" allowfullscreen allow="autoplay">
</iframe>
<div id="code-from-the-video-1" class="section level3">
<h3>Code from the video</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests <span class="co"># For downloading the website</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup <span class="co"># For parsing the website</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time <span class="co"># To put the system to sleep</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random <span class="co"># for random numbers</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Building a scraper</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># The idea here is to just wrap the above in a function.</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Input: url</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: relevant content</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bbc_scraper(url<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Download the webpage</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    page <span class="op">=</span> requests.get(url)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If a connection was reached</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> page.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Parse</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        soup <span class="op">=</span> BeautifulSoup(page.content, <span class="st">&#39;html.parser&#39;</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pull Headline</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>        story_headline <span class="op">=</span> soup.find_all(<span class="st">&quot;h1&quot;</span>)[<span class="dv">0</span>].get_text()</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pull Date</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>        story_date <span class="op">=</span> soup.select(<span class="st">&quot;article &gt; header &gt; div:nth-child(2) &gt; dl &gt; div &gt; dd &gt; span &gt; time&quot;</span>)[<span class="dv">0</span>].get_text()</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Pull story content</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>        story_content <span class="op">=</span> [i.get_text() <span class="cf">for</span> i <span class="kw">in</span> soup.select(<span class="st">&quot;article &gt; div &gt; div&quot;</span>)]</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        story_text <span class="op">=</span> <span class="st">&quot; &quot;</span>.join(story_content)</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return data</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [story_headline,story_date,story_text]</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract one webpage</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>bbc_scraper(<span class="st">&quot;https://www.bbc.com/news/world-us-canada-54238936&quot;</span>)</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Now loop through urls of relevant stories</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s collect urls on all the relevant news stories of the day.</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>urls <span class="op">=</span> [<span class="st">&quot;https://www.bbc.com/news/world-us-canada-54238936&quot;</span>,</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;https://www.bbc.com/news/world-us-canada-54254141&quot;</span>,</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;https://www.bbc.com/news/world-us-canada-54229799&quot;</span>,</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;https://www.bbc.com/news/world-us-canada-54244515&quot;</span>]</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a><span class="co">#Then just loop through and collect</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>scraped_data <span class="op">=</span> []</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> url <span class="kw">in</span> urls:</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Scrape the content</span></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    scraped_data.append(bbc_scraper(url))</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Put the system to sleep for a random draw of time (be kind)</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    time.sleep(random.uniform(<span class="fl">.5</span>,<span class="dv">3</span>))</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at the data object</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>scraped_data</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Organize as a pandas data frame</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.DataFrame(scraped_data,columns<span class="op">=</span>[<span class="st">&quot;headline&quot;</span>,<span class="st">&quot;date&quot;</span>,<span class="st">&quot;content&quot;</span>])</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>dat.to_csv(<span class="st">&quot;scraped_web_data.csv&quot;</span>,index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a><span class="co"># How to locate URLS?</span></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>main_bbc_page_url <span class="op">=</span> <span class="st">&quot;https://www.bbc.com/news&quot;</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>main_page <span class="op">=</span> requests.get(main_bbc_page_url)</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>main_page.status_code</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>main_soup <span class="op">=</span> BeautifulSoup(main_page.content,<span class="st">&#39;html.parser&#39;</span>)</span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a>tag <span class="op">=</span> main_soup.find_all(<span class="st">&quot;a&quot;</span>)[<span class="dv">10</span>]</span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a>tag.attrs.get(<span class="st">&quot;href&quot;</span>)</span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract relevant links</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>links <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tag <span class="kw">in</span> main_soup.find_all(<span class="st">&quot;a&quot;</span>):</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>    href <span class="op">=</span> tag.attrs.get(<span class="st">&quot;href&quot;</span>)</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&quot;world-us-canada&quot;</span> <span class="kw">in</span> href <span class="kw">and</span> <span class="st">&quot;https:&quot;</span> <span class="kw">not</span> <span class="kw">in</span> href:</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>        links.update([<span class="st">&quot;https://www.bbc.com&quot;</span> <span class="op">+</span> href])</span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>links</span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s write the above as a single function</span></span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> link_scrape(urls<span class="op">=</span><span class="va">None</span>,sleep<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Scrape multiple BBC URLS.</span></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a><span class="co">        urls (list): list of valid BBC news urls.</span></span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a><span class="co">        sleep (int): Integer value specifying how long the machine should be</span></span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a><span class="co">                    put to sleep (random uniform). Defaults to 3.</span></span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a><span class="co">        DataFrame: frame containing headline, date, and content fields</span></span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>    scraped_data <span class="op">=</span> []</span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> url <span class="kw">in</span> urls:</span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(url) <span class="co"># Keep track of where we are at.</span></span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Scrape the content This will break on URLs that we haven&#39;t</span></span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a>            <span class="co"># accounted for the structure on. So we&#39;ll use a try and except </span></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a>            <span class="co"># clause so our code continues even though it breaks on some urls. </span></span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a>            scraped_data.append(bbc_scraper(url))</span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span>:</span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&quot;URL doesn&#39;t work with scraper&quot;</span>)</span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Put the system to sleep for a random draw of time (be kind)</span></span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a>        time.sleep(random.uniform(<span class="dv">0</span>,sleep))</span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>    dat <span class="op">=</span> pd.DataFrame(scraped_data,columns<span class="op">=</span>[<span class="st">&quot;headline&quot;</span>,<span class="st">&quot;date&quot;</span>,<span class="st">&quot;content&quot;</span>])</span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dat</span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a>dat_content <span class="op">=</span> link_scrape(urls<span class="op">=</span>links)</span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a>dat_content</span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a><span class="co"># More advanced approaches to scraping the web.</span></span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a><span class="co"># https://scrapy.org/</span></span></code></pre></div>
<br>
<hr>
<p><br></p>
</div>
</div>
<div id="scraping-.pdf.docx" class="section level2">
<h2>Scraping <code>.pdf</code>/<code>.docx</code></h2>
<p><br></p>
<iframe src="https://georgetown.hosted.panopto.com/Panopto/Pages/Embed.aspx?id=2dafea85-1073-4bfe-afa8-ac3f011ecd21&amp;autoplay=false&amp;offerviewer=true&amp;showtitle=true&amp;showbrand=false&amp;start=0&amp;interactivity=all" height="506" width="900" style="border: 1px solid #464646;" allowfullscreen allow="autoplay">
</iframe>
<p><br></p>
<p>Download the documents being scraped in this video:</p>
<ul>
<li><a href="data/documents_scraped_in_async/mercy_corp.pdf" download><strong>mercy_corp.pdf</strong></a></li>
<li><a href="data/documents_scraped_in_async/thomas_wood.pdf" download><strong>thomas_wood.pdf</strong></a></li>
<li><a href="data/documents_scraped_in_async/Easterly_and_Levine.docx" download><strong>Easterly_and_Levine.docx</strong></a></li>
</ul>
<p><br></p>
<div id="code-from-the-video-2" class="section level3">
<h3>Code from the video</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install PyPDF2</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip3 install python-docx</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> PyPDF2 <span class="co"># Scraping PDFs</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> docx <span class="co"># Scraping Word Documents</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&quot;ignore&quot;</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">########## Scraping TEXT in a PDF ###########</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#############################################</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Mercy Corp Report As example</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.mercycorps.org/sites/default/files/2019-11/Motivations%20and%20Empty%20Promises_Mercy%20Corps_Full%20Report_0.pdf</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>pdfFileObj <span class="op">=</span> <span class="bu">open</span>(<span class="st">&#39;mercy_corp.pdf&#39;</span>, <span class="st">&#39;rb&#39;</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>pdfReader <span class="op">=</span> PyPDF2.PdfFileReader(pdfFileObj)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>pdfReader.numPages</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>pdfReader.isEncrypted</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>pageObj <span class="op">=</span> pdfReader.getPage(<span class="dv">10</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pageObj.extractText())</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>pdfFileObj.close()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract all the text content in the PDF</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_pdf(<span class="bu">file</span>):</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="bu">file</span>, <span class="st">&#39;rb&#39;</span>) <span class="im">as</span> pdfFileObj:</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Open the pdf</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        pdfReader <span class="op">=</span> PyPDF2.PdfFileReader(pdfFileObj)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Locate the number of pages</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        n_pages <span class="op">=</span> pdfReader.numPages</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loop through the pages and store the content by</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># appending to a string</span></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>        content <span class="op">=</span> <span class="st">&quot;&quot;</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_pages):</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>            content <span class="op">+=</span> pdfReader.getPage(i).extractText()</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> content</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a><span class="co"># Examine the content</span></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>mc_content <span class="op">=</span> read_pdf(<span class="st">&quot;mercy_corp.pdf&quot;</span>)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(mc_content)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">CAUTION</span><span class="co">! Not all PDFs are equal. Some are really difficult to parse.</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Given that the spaces aren&#39;t special characters.</span></span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>tw_content <span class="op">=</span> read_pdf(<span class="st">&quot;thomas_wood.pdf&quot;</span>)</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tw_content)</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a><span class="co"># When you run into this, you&#39;ll have to think through an alternative parsing strategy. No free lunch here.</span></span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a><span class="co">################################################</span></span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a><span class="co">########## Scraping TEXT in WORD doc ###########</span></span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a><span class="co">################################################</span></span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> docx.Document(<span class="st">&quot;Easterly_and_Levine.docx&quot;</span>)</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a><span class="bu">dir</span>(doc)</span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(doc.paragraphs)</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(doc.paragraphs[<span class="dv">0</span>].text)</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> doc.paragraphs:</span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(i.text)</span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a><span class="co"># %% -----------------------------------------</span></span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrap into a function</span></span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_word(filename):</span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> docx.Document(filename)</span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a>    fullText <span class="op">=</span> []</span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> para <span class="kw">in</span> doc.paragraphs:</span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a>        fullText.append(para.text)</span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>.join(fullText)</span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(get_word(<span class="st">&quot;Easterly_and_Levine.docx&quot;</span>))</span></code></pre></div>
<br>
<hr>
<p><br></p>
</div>
</div>
</div>
<div id="practice" class="section level1 tabset tabset-pills">
<h1 class="tabset tabset-pills">Practice</h1>
<p><br></p>
<p>These exercises are designed to help you reinforce your grasp of the concepts covered in the asynchronous lecture material.</p>
<p><br></p>
<p>For the following question, let’s use this Wikipedia page to practice some of the webscraping concepts covered in the asynchronous lecture.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>wiki_url <span class="op">=</span> <span class="st">&quot;https://en.wikipedia.org/wiki/Machine_learning&quot;</span></span></code></pre></div>
<p><br></p>
<div id="section-1" class="section level2">
<h2>_</h2>
</div>
<div id="question-1" class="section level2 tabset">
<h2 class="tabset">Question 1</h2>
<p><br></p>
<p>Download the website of the Wikipedia article and parse the webcontent.</p>
<p><br></p>
<div id="section-2" class="section level3">
<h3>_</h3>
</div>
<div id="answer" class="section level3">
<h3>Answer</h3>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bs4 <span class="im">import</span> BeautifulSoup</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>wiki <span class="op">=</span> requests.get(wiki_url)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>wiki_parsed <span class="op">=</span> BeautifulSoup(wiki.content, <span class="st">&quot;html.parser&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="question-2" class="section level2 tabset">
<h2 class="tabset">Question 2</h2>
<p><br></p>
<p>Scrape the <strong><em>title</em></strong> and <strong><em>subtitles</em></strong> from the Wikipedia article.</p>
<p><br></p>
<div id="section-3" class="section level3">
<h3>_</h3>
</div>
<div id="answer-1" class="section level3">
<h3>Answer</h3>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scrape the main title of the article </span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>article_title <span class="op">=</span> wiki_parsed.find_all(<span class="st">&quot;h1&quot;</span>)[<span class="dv">0</span>].get_text()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Scrape the subtitles of the article</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>article_subtitles <span class="op">=</span> [h.get_text() <span class="cf">for</span> h <span class="kw">in</span> wiki_parsed.find_all(class_<span class="op">=</span><span class="st">&quot;mw-headline&quot;</span>)]</span></code></pre></div>
</div>
</div>
<div id="question-3" class="section level2 tabset">
<h2 class="tabset">Question 3</h2>
<p><br></p>
<p>Scrape the <strong><em>text content</em></strong> from the Wikipedia article. Make sure the content is collapsed into a single character string.</p>
<p><br></p>
<div id="section-4" class="section level3">
<h3>_</h3>
</div>
<div id="answer-2" class="section level3">
<h3>Answer</h3>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>content <span class="op">=</span> [p.get_text() <span class="cf">for</span> p <span class="kw">in</span> wiki_parsed.find_all(<span class="st">&quot;p&quot;</span>)]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>.join(content)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(text)</span></code></pre></div>
</div>
</div>
</div>

&nbsp;
<hr />
<p style="text-align: center;"><em>The following materials were generated for students enrolled in PPOL564. Please do not distribute without permission.</em></p>
<p style="text-align: center;"><span style="color: #808080;"><em>ed769@georgetown.edu | www.ericdunford.com</em></span></p>

&nbsp;



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
